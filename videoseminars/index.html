<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<link rel="icon" href="http://www.csc.kth.se/favicon.ico">
<link rel="stylesheet" type="text/css" href="../index-filer/kod-html.css">


<title>
Jakob Nordström: Video seminars</title>
</head>
<body>

<table class="innehall_ram" width="634" cellspacing="0" cellpadding="0" border="0">
<tbody><tr>

<td valign="top">
<div class="innehall">
<a name="topofpage"></a>


<!-- Hard-coded "menu" at top of page -->

<table width="100%">
<tbody><tr><td valign="top" align="left">
<span class="sokvag_nedflyttad">
  <a href="http://www.jakobnordstrom.se">Jakob Nordström</a>
/ Video seminars</span>
</td>
</tr>
</tbody></table>


<h1>
  MIAO  Video Seminars
</h1>

<p> 

  The
  <em>MIAO  video seminars</em>
  are what we call the series of seminars arranged  by the
  <a href="http://www.jakobnordstrom.se/miao-group/">Mathematical
    Insights into Algorithms for Optimization (MIAO)
    research group</a>
    at the University of Copenhagen and Lund University.
</p>

<p>
  These seminars are typically fairly low-key, informal events, but
  they are usually open to the publix and are announced beforehand on
  our seminar mailing lists (with two different lists for more
  theoretically oriented or more applied seminars, respectively).  In
  case you want to receive the announcements, please just let us know
  by sending an e-mail message to jakob.nordstrom@cs.lth.se and we
  will add you to the relevant list(s).
</p>
  
<p>
  In response to multiple requests, since the spring
  of 2021 we have started posting most seminars on the
  <a href="https://www.youtube.com/channel/UCN0G2Wfl9-sAKrVLVza7z4A">MIAO
    Research YouTube channel</a>.
  
</p>

  <h2>Upcoming video seminars</h2>
  
  
<p>
  <em>
    It seems that the MIAO video seminars have mostly switched to
    vacation mode, but we plan to be back in late August. Please note that the dates below are still a bit tentative, though.
    All times below are in the Central European time zone (with or without daylight savings as appropriate).
  </em>
</p>

<p>


</p>

<ul>
  
  <li>
    <p>
      Friday August 27 at 14:00
      <br>
      <strong>
	Title TBD
      </strong>
      <br>
      (Dmitriy Traytel, University of Copenhagen)
    </p>
    
    <p>
    </p>
      
  <li>
    <p>
      Monday September 6 at 14:00
      <br>
      <strong>
	Lifting with sunflowers
      </strong>
      <br>
      (Ian Mertz, University of Toronto)
    </p>
    
    <p>
      Lifting theorems are an important class of techniques which
      can transform functions which are hard for weak computation
      models into functions which are hard for strong computation
      models. Starting with Raz and McKenzie (1999), there has been
      a flurry of work proving query-to-communication lifting
      theorems, which translate lower bounds on query complexity to
      lower bounds for the corresponding communication model. In
      this talk I will present a simplified proof of deterministic
      query-to-communication lifting. Our proof uses elementary
      counting together with a novel connection to the sunflower
      lemma.	
    </p>

  <li>
    <p>
      Monday September 13 at 14:00
      <br>
      <strong>
	Title TBD
      </strong>
      <br>
      (Sajin Koroth, Simon Fraser University)
    </p>
    
  <li>
    <p>
      Monday September 20 at 14:00
      <br>
      <strong>
	The KRW conjecture
      </strong>
      <br>
      (Or Meir, University of Haifa)
    </p>
    
    <p>
      Proving super-logarithmic lower bounds on the depth of
      circuits is one of the main frontiers of circuit
      complexity. In 1991, Karchmer, Raz and Wigderson observed that
      we could resolve this question by proving the following
      conjecture: Given two boolean functions <em>f</em>,<em>g</em>, the depth
      complexity of their composition is about the sum of their
      individual depth complexities. While we cannot prove the
      conjecture yet, there has been some exciting progress toward
      such a proof, some of it in the last few years. In this talk,
      I will survey the known results and propose future directions
      for research on the KRW conjecture.
    </p>

  <li>
    <p>
      Monday September 27 at 14:00
      <br>
      <strong>
	Title TBD
      </strong>
      <br>
      (Arkadev Chattopadhyay, Tata Institute of Fundamental Research, Mumbai)
    </p>
    
    
  <li>
    <p>
      Friday October 1 at 14:00
      <br>
      <strong>
	Title TBD
      </strong>
      <br>
      (Mika Göös, EPFL)
    </p>      
    
  <li>
    <p>
      Date and time TBD
      <br>
      <strong>
	Automating algebraic proof systems is <em>NP</em>-hard
      </strong>
      <br>
      (Susanna F. de Rezende,
      Institute of Mathematics of the Czech Academy of Sciences)
    </p>      
    
    <p>
      Intuitively, automatability addresses the proof search
      problem: How hard is it to find a proof? In this talk, we will
      show that algebraic proofs are hard to find: Given an
      unsatisfiable CNF formula <em>F</em>, it is <em>NP</em>-hard to find a
      refutation of <em>F</em> in the Nullstellensatz, Polynomial Calculus,
      or Sherali-Adams proof systems in time polynomial in the size
      of the shortest such refutation. We will first present a
      simplified proof of the recent breakthrough of Atserias and
      Müller (FOCS 2019) that established an analogous result for
      Resolution and then explain how we generalise it to algebraic
      proof systems.
    </p>
    
    <p>
      This talk is based on joint work with Mika Göös, Jakob
      Nordström, Toniann Pitassi, Robert Robere, and Dmitry Sokolov.
    </p>
    
    
</ul>

  
<p></p>

  <h2>Video seminars spring 2021</h2>
  

<p>
    
  <em>
    During the spring semester of 2021,
    we had    online virtual seminars running every weekday
    at 17:30 CET from early February to mid-May
    as part of the 
    <a href="https://simons.berkeley.edu/programs/sat2021">Satisfiability: Theory, Practice, and Beyond</a>
    and
    <a href="https://simons.berkeley.edu/programs/tfcs2021">Theoretical Foundations of Computer Systems</a>
    programs
    at the
    <a href="https://simons.berkeley.edu/">Simons Institute
      for the Theory of Computing</a>.

    On top of this, we had some additional seminars as listed
    below.
  </em>

</p>
  
<p>
    
  </p><ul>
    
    <li>
      <p>
	Monday Jun 7 at 14:00
	<br>
	<strong>
	  Proof complexity meets finite model theory
	</strong>
	(<a href="https://youtu.be/0P0N7ucxFg4">video</a>)	
	<br>
	(Joanna Ochremiak, LaBRI, Université de Bordeaux and CNRS)
      </p>      

      <p>
	Finite model theory studies the power of logics on the class of finite 
structures. One of its goals is to characterize symmetric computation, 
that is, computation that abstracts away details which are not essential
 for the given task, by respecting the symmetries of the input.
      </p>
      
      <p>
	In this talk I will discuss connections between proof complexity and 
finite model theory, focussing on lower bounds. For certain proof 
systems, the existence of a succinct refutation can be decided in a 
symmetry-preserving way. This allows us to transfer lower bounds from 
finite model theory to proof complexity. I will introduce this approach 
and explain its key technical ideas such as the method of folding for 
dealing with symmetries in linear programs.
      </p>


        </li><li>
      <p>
	Friday Jun 4 at 14:00
	<br>
	<strong>
	Abstract cores in implicit hitting set based MaxSAT solving
	</strong>

	(<a href="https://youtu.be/rDz1iVO5Yjg">video</a>)
	<br>
	(Jeremias Berg, University of Helsinki) 
      </p>

      <p>
	Maximum satisfiability (MaxSat) solving is an active area of research 
motivated by numerous successful applications to solving NP-hard 
combinatorial optimization problems. One of the most successful 
approaches for solving MaxSat instances from real world domains are the 
so called implicit hitting set (IHS) solvers. IHS solvers decouple 
MaxSat solving into separate core-extraction and optimization steps 
which are tackled by an Boolean satisfiability (SAT) and an integer 
linear programming (IP) solver, respectively. While the approach shows 
state-of-the-art performance on many industrial instances, it is known 
that there exists instances on which IHS solvers need to extract an 
exponential number of cores before terminating. In this talk I will 
present the  simplest of these problematic instances
	and talk about how abstract cores, a compact representation of a large 
number of regular cores that we recently proposed, addresses perhaps the
 main bottleneck of IHS solvers. I will show how to incorporate abstract
 core reasoning into the IHS algorithm and demonstrate that
	 that including abstract cores into a state-of-the- art IHS solver 
improves its performance enough to surpass the best performing solvers 
of the recent MaxSat Evaluations.
	</p>
      
          
    </li><li>
      <p>
	Friday May 28 at 14:00
	<br>
	<strong>
	  Feasible interpolation for algebraic proof systems
	</strong>
	(<a href="https://youtu.be/S8N3-089LQQ">video</a>)
	<br>
	(Tuomas Hakoniemi,
	Universitat Politècnica de Catalunya)
      </p>

      <p>
	In this talk we present a form of feasible interpolation for two 
algebraic proof systems, Polynomial Calculus and Sums-of-Squares. We 
show that for both systems there is a poly-time algorithm that given two
 sets <em>P(x,z)</em> and <em>Q(y,z)</em> of polynomial equalities, a refutation of the union of <em>P(x,z)</em> and <em>Q(y,z)</em> and an assignment <em>a</em> to the <em>z</em>-variables outputs either a refutation of <em>P(x,a)</em> or a refutation of <em>Q(y,a).</em>
 Our proofs are fairly logical in nature, in that they rely heavily on 
semantic characterizations of resource-bounded refutations to prove the 
existence of suitable refutations. These semantic existence proofs 
narrow down the search space for the refutations we are after so that we
 can actually find them efficiently.
	</p>
      
    </li><li>
      <p>
	Monday May 17 at 14:00
	<br>
	<strong>
	  Average-case perfect matching lower bounds
	  from hardness of Tseitin formulas	    
	</strong>
	(<a href="https://youtu.be/1Ha50m1p_Ck">video</a>)
	<br>
	(Kilian Risse, KTH Royal Institute of Technology)
      </p>
      
      
      <p>
	We study the complexity of proving that a sparse random regular
	graph on an odd number of vertices does not have a perfect matching,
	and related problems involving each vertex being matched some
	pre-specified number of times.
	We show that this requires proofs of degree &#937;(n / log n) in
	the Polynomial Calculus (over fields of characteristic &#8800; 2) and
	Sum-of-Squares proof systems, and exponential size in the
	bounded-depth Frege proof system.
	This resolves a question by Razborov asking whether
	the LovÃ¡sz-Schrijver proof system requires n<sup>&#948;</sup>
	rounds to refute these formulas for some &#948; &gt; 0.
	The results are obtained by a
	worst-case to average-case reduction of these formulas relying on a
	topological embedding theorem which may be of independent interest.
      </p>
      
      <p>Joint work with with Per Austrin.
      </p>
      
    
    </li><li>
      <p>
	Monday May 10 at 14:00
	<br>
	<strong>
	  On the complexity of branch and cut
	</strong>
	(<a href="https://youtu.be/WgfWXXW2BqA">video</a>)
	<br>
	(Noah Fleming, University of Toronto)
      </p>      
      
      <p>
	The Stabbing Planes proof system was introduced to model practical 
branch-and-cut integer programming solvers. As a proof system, Stabbing 
Planes can be viewed as a simple generalization of DPLL to reason about 
linear inequalities. It is powerful enough to simulate Cutting Planes 
and produce short refutations of the Tseitin formulas — certain 
unsatisfiable systems of linear equations mod 2 — which are canonical 
hard examples for many algebraic proof systems. In a surprising recent 
result, Dadush and Tiwari showed that these short Stabbing Planes 
refutations of the Tseitin formulas could be translated into Cutting 
Planes proofs. This raises the question of whether all Stabbing Planes 
can be efficiently translated into Cutting Planes. In recent work, we 
give a partial answer to this question.
      </p>
      
      <p>
	In this talk I will introduce and motivate the Stabbing Planes proof 
system. I will then show how Stabbing Planes proofs with 
quasi-polynomially bounded coefficients can be quasi-polynomially 
translated into Cutting Planes. As a consequence of this translation, we
 can show that Cutting Planes has quasi-polynomial size refutations of 
any unsatisfiable system of linear equations over a finite field. A 
remarkable property of our translation for systems of linear equations 
over finite fields, and the translation of Dadush and Tiwari for the 
Tseitin formulas, is that the resulting proofs are also 
quasi-polynomially deep. A natural question is thus whether these depth 
bounds can be improved. In the last part of the talk, I will discuss 
progress towards answering this question in the form of a new depth 
lower bound technique for Cutting Planes, which works also for the 
stronger semantic Cutting Planes system, and which allows us to 
establish the first linear lower bounds on the depth of semantic Cutting
 Planes refutations of the Tseitin formulas.
      </p>
      

    </li><li>
      <p>
	Monday May 3 at 14:00 <br>
	<strong>
	  SAT-encodings and scalability
	</strong>
	(<a href="https://youtu.be/tXIGe71yFwI">video</a>)
	<br> 
	(André Schidler, Technische Universität Wien)
      </p>
      
      <p>
	Boolean satisfiability (SAT) solvers have reached stunning performance 
over the last decade. This performance can be harnessed for other 
problems by means of SAT encodings: translating the problem instance 
into a SAT instance. SAT encodings have been used successfully for many 
combinatorial problems and are established in industry. In this talk, I 
discuss the general idea behind SAT encodings and two specific 
application areas: graph decompositions and machine learning.
      </p>
      
      <p>
	Graph decompositions allow for specialized algorithms that can solve 
hard problems efficiently. SAT encodings provide not only the means to 
optimally compute these decompositions, but can be easily extended by 
extra constraints specific to the hard problem to be solved.
      </p>

      <p>
	For machine learning, SAT encodings gained increased attention in 
recent years, as they allow the induction of very small AI models. 
Learning small models has become more important in the context of 
explainable AI: smaller models are usually easier to understand for 
humans. We will focus specifically on decision tree induction.
      </p>
      
      <p>
	Scalability is one of the main issues when using SAT encodings. We can 
overcome this problem by embedding SAT-based solving into a heuristic 
framework. This allows us to trade off a slightly worse result for large
 applicability. In the last part of our talk, we discuss our SAT-based 
local improvement framework that implements this idea.
	</p>

    </li><li>
      <p>
	Wednesday Apr 28 at 15:00
	<br>
	<strong>
	  Slicing the hypercube is not easy
	</strong>
	(<a href="https://youtu.be/arbxOTjsQZQ">video</a>)
	<br>
	(Amir Yehudayoff, Technion – Israel Institute of Technology)
      </p>
      
      <p>
	
	How many hyperplanes are needed to slice all edges of the hypercube? 
This question has been studied in machine learning, geometry and 
computational complexity since the 1970s. We shall describe (most of) an
 argument showing that more than <em>n</em><sup>0.57</sup> hyperplanes are needed, for large&nbsp;<em>n</em>. We shall also see a couple of applications. This is joint work with Gal Yehuda.
      </p>
      

    
    </li><li>
      <p>
	Monday Apr 26 at 14:00
	<br>
	<strong>
	  Recent lower bounds in algebraic complexity theory
	</strong>
	(<a href="https://youtu.be/1yRkXzmu8Hg">video</a>)
	<br>
	(Ben Lee Volk, University of Texas at Austin)
      </p>
      
      <p>
	Algebraic complexity theory studies the complexity of solving algebraic
 computational tasks using algebraic models of computation. One major 
problem in this area is to prove lower bounds on the number of 
arithmetic operations required for computing explicit polynomials. This 
natural mathematical problem is the algebraic analog of the famous <em>P</em> vs. <em>NP</em> problem. It also has tight connections to other classical mathematical areas and to fundamental questions in complexity theory.
      </p>
	
      <p>
	In this talk I will provide background and then present some recent 
progress on proving lower bounds for models of algebraic computation, 
such as the algebraic analogs of <em>NC</em><sup>1</sup> and <em>NL</em>.
      </p>
      
      <p>
	Based on joint works with Prerona Chatterjee, Mrinal Kumar, and Adrian She.
      </p>		
    
    </li><li>
	<p>
	  Friday Apr 23 at 14:00
	  <br>
	  <strong>
	    On the complexity of branching proofs
	  </strong>
	  (<a href="https://youtu.be/3wxIuNJp1Gw">video</a>)
	  <br>
	  (Daniel Dadush, CWI)
	</p>
	
	<p>
	  We consider the task of proving integer infeasibility of a bounded
	  convex <em>K</em> in <em>R<sup>n</sup></em> using a general branching
	  proof system. In a general branching proof, one constructs a branching
	  tree by adding an integer disjunction <em>ax &#10877; b</em> or
	  <em>ax &#10878; b+1</em>, for an integer vector <em>a</em> and an
	  integer <em>b</em>, at each node, such that the leaves of the tree
	  correspond to empty sets (i.e., <em>K</em> together with the
	  inequalities picked up from the root to leaf is empty). Recently,
	  Beame et al (ITCS 2018), asked whether the bit size of the
	  coefficients in a branching proof, which they named stabbing planes
	  (SP) refutations, for the case of polytopes derived from SAT formulas,
	  can be assumed to be polynomial in <em>n</em>. We resolve this
	  question by showing that any branching proof can be recompiled so that
	  the integer disjunctions have coefficients of size at most
	  <em>(nR)<sup>O(n2)</sup></em>, where <em>R</em> is the radius of an
	  <em>l<sub>1</sub></em> ball containing <em>K</em>,  while increasing
	  the number of nodes in the branching tree by at most a factor
	  <em>O(n)</em>. As our second contribution, we show that Tseitin
	  formulas, an important class of infeasible SAT instances, have
	  quasi-polynomial sized cutting plane (CP) refutations, disproving the
	  conjecture that Tseitin formulas are (exponentially) hard for CP. As
	  our final contribution, we give a simple family of polytopes in
	  <em>[0,1]<sup>n</sup></em> requiring branching proofs of length
	  <em>2<sup>n</sup>/n</em>.
	</p>
	
	<p>
	  Joint work with Samarth Tiwari.
	</p>
	

    
    </li><li>
      <p>
	Monday Apr 19 at 14:00
      <br>
      <strong>
	Kidney exchange programmes —
	saving lives with optimisation algorithms
      </strong>
      (<a href="https://youtu.be/6kQxq-EfVpQ">video</a>)
      <br>
      (William Pettersson, University of Glasgow)
      </p>

      <p>
	Kidney Exchange Programmes (KEPs) increase the rate of living
	donor kidney transplantation, in turn saving lives. In this
	talk, I will explain exactly what KEPs are, how KEPs achieve
	this goal, and the role of optimisation algorithms within
	KEPs. This will include brief explanations of some of the
	models used for kidney exchange programmes, some of the more
	generic optimisation techniques that we use, as well as recent
	advances and specific research directions for the field into
	the future. This talk will very much be an overview of kidney
	exchange, without going into complex details of optimisation
	algorithms, making it suitable for a wider audience.
      </p>
      
    
    </li><li>
      <p>
	Thursday Apr 8 at 14:00
      <br>
      <strong>
	(Semi)Algebraic proofs over {&pm;1} variables
      </strong>
      (<a href="https://youtu.be/trV7ilheKQg">video</a>)
      <br>
      (Dmitry Sokolov, St.Petersburg State University)
      </p>

      <p>
	One of the major open problems in proof complexity is to prove
	lower bounds on AC0[p]-Frege proof systems. As a step toward
	this goal Impagliazzo, Mouli and Pitassi in a recent paper
	suggested proving lower bounds on the size for Polynomial
	Calculus over the {&pm;1} basis. In this talk we show a
	technique for proving such lower bounds and moreover, we also
	give lower bounds on the size for Sum-of-Squares over the
	{&pm;1} basis.
      </p>

      <p>
	We discuss the difference between {0, 1} and {+1, -1} cases and
	problems in further generalizations of the lower bounds.
      </p>


    </li><li>
      <p>
      <em> Courtesy of Zuse Institute Berlin:</em> <br>
      Friday Feb 12 at 14:00
      <br>
      <strong>
	Introduction to IP presolving techniques in PaPILO
      </strong> <br>
      (Alexander Hoen, Zuse Institute Berlin)
      </p>

      <p>
  Presolving is an essential part contributing to the performance of
  modern MIP solvers. PaPILO, a new C++ library, provides presolving
  routines for MIP and LP problems. This talk will give an introduction
  to basic IP-presolving techniques and provide insights into important
  design choices enabling PaPILO's capabilities, in particular
  regarding its use of parallel hardware. While presolving itself is
  designed to be fast, this can come at the cost of failing to find
  important reductions due to working limits and heuristic filtering.
  Yet, even most commercial solvers do not use multi-threading for the
  preprocessing step as of today. PaPILO's design facilitates use of
  parallel hardware to allow for more aggressive presolving and
  presolving of huge problems. The architecture of PaPILO allows
  presolvers generally to run in parallel without requiring expensive
  copies of the problem and without special synchronization in the
  presolvers themselves. Additionally, the use of Intel's TBB library
  aids PaPILO to efficiently exploit recursive parallelism within
  expensive presolving routines, such as probing, dominated columns, or
  constraint sparsification. Despite PaPILO's use of parallelization,
  its results are guaranteed to be deterministic independently of the
  number of threads available.

      </p>

  </li></ul>
  
<h2>Video seminars autumn 2020</h2>


<p>
  
  </p><ul>

    <li>
      <p>
	Friday Oct 9 at 13:15 <br>
	<strong>
	  Model counting with probabilistic component caching
	</strong> <br>
	(Shubham Sharma and Kuldeep S. Meel,
	National University of Singapore)
      </p>

      <p>
	Given a Boolean formula F, the problem of model counting, also
	referred to as #SAT, seeks to compute the number of solutions of F.
	Model counting is a fundamental problem with a wide variety of
	applications ranging from planning, quantified information flow to
	probabilistic reasoning and the like. The modern #SAT solvers tend to
	be either based on static decomposition, dynamic decomposition, or a
	hybrid of the two. Despite dynamic decomposition based #SAT solvers
	sharing much of their architecture with SAT solvers, the core design
	and heuristics of dynamic decomposition-based #SAT solvers has
	remained constant for over a decade. In this paper, we revisit the
	architecture of the state-of-the-art dynamic decomposition-based #SAT
	tool, sharpSAT, and demonstrate that by introducing a new notion of
	probabilistic component caching and the usage of universal hashing
	for exact model counting along with the development of several new
	heuristics can lead to significant performance
	improvement over state-of-the-art model-counters. In particular, we
	develop GANAK, a new scalable probabilistic exact model counter that
	outperforms state-of-the-art exact and approximate model counters for
	a wide variety of instances.
      </p>

    </li><li>
      <p>
	Friday Sep 25 at 13:15 <br>
	<strong>
	  Manthan: A data-driven approach for Boolean function synthesis
	</strong> <br>
	(Priyanka Golia and Kuldeep S. Meel,
	National University of Singapore)
      </p>

      <p>
	Boolean functional synthesis is a fundamental problem in computer
	science with wide-ranging applications and has witnessed a surge of
	interest resulting in progressively improved techniques over the past
	decade. Despite intense algorithmic development, a large number of
	problems remain beyond the reach of the current state-of-the-art
	techniques. Motivated by the progress in machine learning, we propose
	Manthan, a novel data-driven approach to Boolean functional
	synthesis. Manthan views functional synthesis as a classification
	problem, relying on advances in constrained sampling for data
	generation, and advances in automated reasoning for a novel
	proof-guided refinement and provable verification. On an extensive
	and rigorous evaluation over 609 benchmarks, we demonstrate that
	Manthan significantly improves upon the current state of the art,
	solving 356 benchmarks in comparison to 280, which is the most solved
	by a state-of-the-art technique; thereby, we demonstrate an increase
	of 76 benchmarks over the current state of the art. The significant
	performance improvements, along with our detailed analysis, highlights
	several interesting avenues of future work at the intersection of
	machine learning, constrained sampling, and automated reasoning.
      </p>

      

    </li><li>
      <p>
	Friday Aug 28 at 13:15 <br>
	<strong>
	  Tuning Sat4j PB solvers for decision problems
	</strong> <br>
	(Romain Wallon,
	Université d'Artois)
      </p>
      <p>
	During the last decades, many improvements in CDCL SAT solvers have 
made possible to solve efficiently large problems containing millions of
 variables and clauses.
	Despite this practical efficiency, some instances remain out of reach 
for such solvers.
	This is particularly true when the input formula requires an 
exponential size refutation proof in the resolution proof system (as for
 pigeonhole formulae).
	This observation motivated the development of another kind of solvers, 
known as pseudo-Boolean (PB) solvers.
	These solvers take as inputs a conjunction of PB constraints (integral 
linear inequations over Boolean variables) and benefit from the cutting 
planes proof system, which is (in theory) stronger than the resolution 
proof system.
	To implement this proof system, current PB solvers follow the direction
 of modern SAT solvers, by implementing a conflict analysis procedure 
relying on the application of cutting planes rules.
	However, adapting the CDCL architecture to take into account PB 
constraints is not as straightforward as it may look.
	In particular, many CDCL invariants and properties do not hold anymore 
as long as PB constraints are considered.
	While some of them may be safely ignored (e.g., when they affect the 
decision heuristic, the deletion strategy or the restart policy), some 
others must be fixed to ensure the soundness of the solver (e.g., by 
ensuring to preserve the conflict during its analysis).
      </p>
      <p>	
	In this talk, we will give an overview of the main differences between 
PB solving and classical SAT solving, and present different approaches 
that have been designed to take these differences into account to extend
 the CDCL architecture to PB problems.
	We will in particular discuss the pros and cons of these approaches, 
and we will explain how they can be enhanced to improve the practical 
performance of PB solvers.
      </p>
      
    </li><li>
      <p>
	Friday Aug 21 at 10:15 <br>
	<strong>
	  Using proofs to analyze SAT solvers
	</strong> <br>
	(Janne Kokkala,
	Lund University and University of Copenhagen)
      </p>

      <p>

	The main idea of this seminar is to give an overview of what
	one can ask and what one can learn about SAT solvers when
	analyzing the proof to estimate what part of the work was
	useful. I will start by giving a 17-ish minute alpha test run
	for my presentation for our CP paper [1]. After that, I will
	discuss earlier works that use the same or a similar idea for
	general insights [2], analyzing VSIDS usefulness [3], and
	clause exchange for parallel solvers [4,5]. To conclude, we
	can discuss how this approach could be used for pseudo-Boolean
	solvers.
      </p>

      <p>
	[1] J. I. Kokkala, J. Nordström.
	    <a href="http://www.csc.kth.se/~jakobn/research/UsingProofs_CP.pdf">Using Resolution Proofs to
	      Analyse CDCL SAT solvers.</a>
	    
	  <br>	
	    [2] L. Simon.
	    <a href="https://pdfs.semanticscholar.org/2064/7856995db578bb90a9e9c5448304850d05f0.pdf">Post Mortem Analysis of SAT Solver Proofs.</a>
	    
	  <br>	
	    [3] S. Malik, V. Ying.
	    <a href="https://www.victoraying.com/talks/fields_2016_sat_efficiency.pdf">On the efficiency of the VSIDS decision heuristic.</a>
	    (Workshop presentation.)
	    
	    
	  <br>	
	    [4] G. Audemard, L. Simon.
	    <a href="http://www.cril.univ-artois.fr/articles/syrup.pdf">Lazy
	      clause exchange policy for parallel SAT solvers.</a>

	  <br>	
	    [5] G. Katsirelos, A. Sabharwal, H. Samulowitz, L. Simon.
	    <a href="https://miat.inrae.fr/katsirelos/papers/ksssaaai13.pdf">Resolution and parallelizability: Barriers to the efficient
	      parallelization of SAT solvers.</a>
	
      </p>
      
    </li><li>
      <p>
	Wednesday Aug 19 at 13:15 <br>
	<strong>
	  On computational aspects of the antibandwidth problem
	</strong> <br>
	(Markus Sinnl,
	Johannes Kepler University Linz)
      </p>

      <p>
	In this talk, we consider the antibandwidth problem, also
	known as dual bandwidth problem, separation problem and
	maximum differential coloring problem. Given a labeled graph
	(i.e., a numbering of the vertices of a graph), the
	antibandwidth of a node is defined as the minimum absolute
	difference of its labeling to the labeling of all its adjacent
	vertices. The goal in the antibandwidth problem is to find a
	labeling maximizing the antibandwidth. The problem is NP-hard
	in general graphs and has applications in diverse areas like
	scheduling, radio frequency assignment, obnoxious facility
	location and map-coloring.
      </p>

      <p>
	There has been much work on deriving theoretical bounds for
	the problem and also in the design of metaheuristics in recent
	years. However, the optimality gaps between the best known
	solution values and reported upper bounds for the
	HarwellBoeing Matrix-instances, which are the commonly used
	benchmark instances for this problem, were often very large
	(e.g., up to 577%).
      </p>

      <p>
	We present new mixed-integer programming approaches for the
	problem, including one approach, which does not directly
	formulate the problem as optimization problem, but as a series
	of feasibility problems. We also discuss how these feasibility
	problems can be encoded with various SAT-encodings, including
	a new and specialised encoding which exploits a certain
	staircase-structure occuring in the problem formulation. We
	present computational results for all the algorithms,
	including a comparison of the MIP and SAT-approaches. Our
	developed approaches allow to find the proven optimal solution
	for eight instances from literature, where the optimal
	solution was unknown and also provide reduced gaps for eleven
	additional instances, including improved solution values for
	seven instances, the largest optimality gap is now
	46%. Instances based on the problem were submitted to the SAT
	Competition 2020.	
      </p>

  </li></ul>

  <p>
  
</p><h2>Video seminars spring 2020</h2>


<p>
  
</p><ul>
    <li>
      <p>
	Wednesday Jul 15 at 15:00 <br>
	<strong>
	  Naïve algorithm selection for SAT solving
	</strong> <br>
	(Stephan Gocht,
	Lund University and University of Copenhagen)
      </p>

      <p>
      Although solving propositional formulas is an NP-complete
      problem, state-of-the-art SAT solvers are able to solve formulas
      with millions of variables. To obtain good performance it is
      necessary to configure parameters for heuristic
      decisions. However, there is no single parameter configuration
      that is perfect for all formulas, and choosing the parameters is
      a difficult task. The standard approach is to evaluate different
      configurations on some formulas and to choose the single
      configuration, that performs best overall. This configuration,
      which is called single best solver, is then used to solve new
      unseen formulas. In this paper we demonstrate how random forests
      can be used to choose a configuration dynamically based on
      simple features of the formula. The evaluation shows that our
      approach is able to outperform the single best solver on
      formulas that are similar to the training set, but not on
      formulas from completely new domains.
      </p>
	
    </li><li>      
      <p>
	Friday Jun 26 at 10:00 <br>
	<strong>
	  Behind the scenes of chronological CDCL
	</strong> <br>
	(Sibylle Möhle and Armin Biere,
	Johannes Kepler University Linz)
      </p>

      <p>	
	Combining conflict-driven clause learning (CDCL) with
	chronological backtracking is challenging: Multiple invariants
	considered crucial in modern SAT solvers are violated, if
	after conflict analysis the solver does not jump to the
	assertion level but to a higher decision level instead. In
	their SAT'18 paper "Chronological Backtracking", Alexander
	Nadel and Vadim Ryvchim provide a fix to this issue. Moreover,
	their SAT solver implementing chronological backtracking won
	the main track of the SAT Competition 2018. In our SAT'19
	paper, "Backing Backtracking", we present a formalization and
	generalization of this method. We prove its correctness and
	provide an independent implementation.
      </p>
      
      <p>
	In this seminar, we demonstrate the working of chronological
	CDCL by means of an example. In this example, after a conflict
	the conflicting clause contains only one literal at conflict
	level. It is therefore used as a reason for backtracking, thus
	saving the effort of conflict analysis. We further show which
	invariants are violated and present new ones followed by a
	discussion of the rules of our formal framework. We also shed
	light onto implementation details, including those which are
	not mentioned in our SAT'19 paper.
      </p>

    </li><li>      
      <p>
	Monday Jun 22 at 13:30 <br>
	<strong>
	  McSplit: A partitioning algorithm for maximum common subgraph
	  problems
	</strong> <br>
	(Ciaran McCreesh and James Trimble,
	University of Glasgow)
      </p>

      <p>
	We will give a short introduction to McSplit, an algorithm for
	the maximum common (connected) subgraph problem coauthored
	with Patrick Prosser and presented at IJCAI 2017. McSplit
	resembles a forward-checking constraint programming algorithm,
	but uses a partitioning data structure to store domains which
	greatly reduces memory use and time per search node. We will
	also present our recent work with Stephan Gocht and Jakob
	Nordström on adding proof logging to the algorithm, turning
	McSplit into a certifying algorithm whose outputs can be
	independently verified.
      </p>

    </li><li>
      <p>
	Thursday Jun 18 at 20:30 <br>
	<strong>
	  A pseudo-Boolean approach to nonlinear verification
	</strong> <br>
	(Vincent Liew,
	University of Washington)
      </p>

      <p>
	We discuss some new experimental results showing the promise
	of using pseudo-Boolean solvers, rather than SAT solvers, to
	verify bit-vector problems containing multiplication. We use
	this approach to efficiently verify the commutativity of a
	multiplier output bit by output bit. We also give some examples
	of simple bit-vector inequalities where the pseudo-Boolean
	approach significantly outperformed SAT solvers and even
	bit-vector solvers. Finally, we give some of our observations on
	the strengths and weaknesses of different methods of conflict
	analysis used by pseudo-Boolean solvers.
      </p>
      
    </li><li>
      <p>
	Friday May 8 at 13:15 <br>
	<strong>
	  Pseudo-Boolean solvers for answer set programming
	</strong> <br>
	(Bart Bogaerts, Vrije Universiteit Brussel)
      </p>

      <p>
      Answer set programming (ASP) is a well-established knowledge
      representation formalism. Most ASP solvers are based on
      (extensions of) technology from Boolean satisfiability
      solving. While these solvers have shown to be very successful in
      many practical applications, their strength is limited by their
      underlying proof system, resolution. In this research, we
      present a new tool LP2PB that translates ASP programs into
      pseudo-Boolean theories, for which solvers based on the
      (stronger) cutting plane proof system exist. We evaluate our
      tool, and the potential of cutting-plane-based solving for ASP
      on traditional ASP benchmarks as well as benchmarks from
      pseudo-Boolean solving. Our results are mixed: overall,
      traditional ASP solvers still outperform our translational
      approach, but several benchmark families are identified where
      the balance shifts the other way, thereby suggesting that
      further investigation into a stronger proof system for ASP is
      valuable.
      </p>

  </li></ul>
  
  
<p>



</p></div>
</td>
</tr>
</tbody></table>

<!-- sidfoten -->
<div class="fotstreck_smalt"></div>
<div class="fotstreck_gratt_med_rutor"></div>
<div class="fotstreck_vitt_med_rutor"></div>
<div class="sidfottext">

<strong>
  Published by:</strong> Jakob Nordström
<a href="mailto:jn~at-sign~di~dot~ku~dot~dk">&lt;jn~at-sign~di~dot~ku~dot~dk&gt;</a>
<br>
Updated 2021-06-26
</div>
<!--/eri-no-index-->



<!-- Default Statcounter code for Jakob's GitHub webpages
https://jakobnordstrom.github.io -->
<script type="text/javascript">
var sc_project=12521096; 
var sc_invisible=1; 
var sc_security="a648a4cc"; 
var sc_remove_link=1; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><img class="statcounter"
src="https://c.statcounter.com/12521096/0/a648a4cc/1/"
alt="Web Analytics Made Easy -
StatCounter"></div></noscript>
<!-- End of Statcounter Code -->


</body></html>

